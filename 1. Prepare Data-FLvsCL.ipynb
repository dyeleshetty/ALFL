{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c89ebd6",
   "metadata": {},
   "source": [
    "# Download KITTI Dataset\n",
    "#### Download KITTI Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ed3e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://s3.eu-central-1.amazonaws.com/avg-kitti/data_object_label_2.zip "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f319e832",
   "metadata": {},
   "source": [
    "#### Download KITTI images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dd5b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://s3.eu-central-1.amazonaws.com/avg-kitti/data_object_image_2.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dedd10e",
   "metadata": {},
   "source": [
    "#### Unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad532d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir KITTI\n",
    "!unzip data_object_label_2.zip ./KITTI/\n",
    "!unzip data_object_image_2.zip ./KITTI/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5d28eb",
   "metadata": {},
   "source": [
    "Images are saved in KITTI\\training\\image_2\\, with labels saved in KITTI\\training\\label_2\\. For every image there is a .png and a .txt file containing the labels. The labels are in a special KITTI format (corner coordinates) and converted to the YOLO format (center coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72861aae",
   "metadata": {},
   "source": [
    "# Converting the dataset\n",
    "We create two seperate datasets: the 8-class dataset that is unbalanced, and the 2-class dataset that only contains pedestrians and cars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81aab248",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAIN_SET = 200\n",
    "DEVICES = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79974a69",
   "metadata": {},
   "source": [
    "### Converting the 8-Class dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b77dc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "KITTI_DIRECTORY = './KITTI/training/'\n",
    "YOLO_DIRECTORY = './KITTI/flcl/'\n",
    "CLASS_MAPPING = {'Car': \"0\",\n",
    " 'Cyclist': \"1\",\n",
    " 'Misc': \"2\",\n",
    " 'Pedestrian': \"3\",\n",
    " 'Person_sitting': \"4\",\n",
    " 'Tram': \"5\",\n",
    " 'Truck': \"6\",\n",
    " 'Van': \"7\"}\n",
    "VALIDATION_SPLIT = 0.30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c466db3e",
   "metadata": {},
   "source": [
    "Create folders for 8-class dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ffb2126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(YOLO_DIRECTORY)\n",
    "os.makedirs(YOLO_DIRECTORY + 'clients/')\n",
    "os.makedirs(YOLO_DIRECTORY + 'train/images/')\n",
    "os.makedirs(YOLO_DIRECTORY + 'train/labels/')\n",
    "os.makedirs(YOLO_DIRECTORY + 'val/images/')\n",
    "os.makedirs(YOLO_DIRECTORY + 'val/labels/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e98345",
   "metadata": {},
   "source": [
    "Create split for training and validationset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "137de39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "random.seed(11111)\n",
    "labels = os.listdir(KITTI_DIRECTORY+\"label_2/\")\n",
    "random.shuffle(labels)\n",
    "split_index = math.floor(len(labels)*VALIDATION_SPLIT)\n",
    "validation = labels[:split_index]\n",
    "train = labels[split_index:]\n",
    "print('Split dataset into {} training items and {} validation items'.format(len(train), len(validation)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d9c0a1",
   "metadata": {},
   "source": [
    "Convert KITTI format to YOLO xywh format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abd6ff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_label(label_file, image_width, image_height):\n",
    "    with open(label_file, 'r') as labelfile:\n",
    "        coords = []\n",
    "        all_labels = []\n",
    "        for line in labelfile:\n",
    "            l = line.split(\" \")\n",
    "            # If the class is unknown, don't include in label file.\n",
    "            if not l[0] in CLASS_MAPPING:\n",
    "                continue\n",
    "            \n",
    "            # Convert coordinates to yolo xywh\n",
    "            coords = list(map(int, map(float, l[4:8])))\n",
    "            x = float((float(coords[2]) + float(coords[0])) / 2.0) / float(image_width)\n",
    "            y = float((float(coords[3]) + float(coords[1])) / 2.0) / float(image_height)\n",
    "            width = float(float(coords[2]) - float(coords[0])) / float(image_width)\n",
    "            height = float(float(coords[3]) - float(coords[1])) / float(image_height)\n",
    "            all_labels.append((CLASS_MAPPING[l[0]], [x, y, width, height]))\n",
    "    return all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfdf935",
   "metadata": {},
   "source": [
    "Use Python Image Library (PIL) to transform the images from png to jpg, to save space and allow more images to be cached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "208bb5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def transform_kitti_file(file, folder_prefix):\n",
    "    fname = (KITTI_DIRECTORY + \"image_2/\" + file).split(\".txt\")[0] + \".png\"\n",
    "    if os.path.isfile(fname):\n",
    "        img = Image.open(fname)\n",
    "        img.save(YOLO_DIRECTORY + folder_prefix + \"/images/\" + file.split(\".txt\")[0] + \".jpg\", \"jpeg\")\n",
    "        labels = transform_label(os.path.join(KITTI_DIRECTORY + \"label_2/\" + file), img.size[0], img.size[1])\n",
    "        if len(labels) == 0:\n",
    "            return\n",
    "        with open(YOLO_DIRECTORY + folder_prefix + \"/labels/\" + file, \"a+\") as yolofile:\n",
    "            for l, c, in labels:\n",
    "                yolofile.write(l + \" \" + str(c[0]) + \" \" + str(c[1]) + \" \" + str(c[2]) + \" \" + str(c[3]) + \"\\n\")\n",
    "    else: \n",
    "        print('Image not found for {}'.format(fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefd9d13",
   "metadata": {},
   "source": [
    "#### Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ead2dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in validation:\n",
    "    transform_kitti_file(f, 'val')\n",
    "for f in train:\n",
    "    transform_kitti_file(f, 'train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caea6392",
   "metadata": {},
   "source": [
    "#### Create overview of all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c65c66db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "with open(YOLO_DIRECTORY + \"train_all.txt\", \"w\") as f_train:\n",
    "    for filename in glob.glob(os.path.join(YOLO_DIRECTORY + \"train/labels/\", \"*.*\")):\n",
    "        f_train.write('%s\\n' % (filename).replace('labels', 'images').replace('.txt', '.jpg'))\n",
    "    \n",
    "# with open(YOLO_DIRECTORY + \"val.txt\", \"w\") as f_val:\n",
    "#     for filename in glob.glob(os.path.join(YOLO_DIRECTORY + \"val/labels/\", \"*.*\")):\n",
    "#         f_val.write('%s\\n' % (filename).replace('labels', 'images').replace('.txt', '.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af8e586",
   "metadata": {},
   "source": [
    "### Create pretrain set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41e2b911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "random.seed(11111)\n",
    "train_all = glob.glob(os.path.join(YOLO_DIRECTORY + \"train/labels/\", \"*.*\"))\n",
    "random.shuffle(train_all)\n",
    "# with open(YOLO_DIRECTORY + \"cl.txt\", \"w\") as f_prefl:\n",
    "#     for filename in train_all[600:600+PRETRAIN_SET]:\n",
    "#         f_prefl.write('%s\\n' % (filename).replace('labels', 'images').replace('.txt', '.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dffe0b",
   "metadata": {},
   "source": [
    "### Split over devices\n",
    "The device split is significantly more difficult due to the need for an unbalanced dataset. We define the deficiencies for each device below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ec933be",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_DEFICIENCIES = {0: {'Cyclist'}, 1:{'Person_sitting'}, 2:{'Cyclist', 'Person_sitting'}, 3: {'Tram', 'Person_sitting'}, \n",
    "                      4: {'Pedestrian', 'Truck'}, 5: {'Truck', 'Cyclist'}, 6: {'Tram', 'Cyclist'}, 7: {'Pedestrian'}, 8: {'Pedestrian', 'Cyclist'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c527f6",
   "metadata": {},
   "source": [
    "Utility functions to distribute the samples over the devices, such that each device has roughly the same amount of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e454e236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribute(samples, devices):\n",
    "    base, extra = divmod(samples, devices)\n",
    "    return [(base + (i < extra),i) for i in range(devices)]\n",
    "\n",
    "def determine_how_many_samples_every_device_should_get(device_samples_original, samples_to_give_away):\n",
    "    equalization_index = 0\n",
    "    device_samples = device_samples_original.copy()\n",
    "    while equalization_index < len(device_samples):\n",
    "        sorted_dict = {k: v for k, v in sorted(device_samples.items(), key=lambda item: item[1], reverse=False)}\n",
    "        if equalization_index + 1 < len(device_samples):\n",
    "            parent = list(sorted_dict.values())[equalization_index+1]\n",
    "            me = list(sorted_dict.values())[equalization_index]\n",
    "            diff = parent-me\n",
    "#             print(f\"equalization_index: {equalization_index}, me: {me}, parent: {parent}, diff: {diff}\")\n",
    "            if diff == 0:\n",
    "                equalization_index +=1\n",
    "                continue\n",
    "            elif diff*(equalization_index+1) < samples_to_give_away:\n",
    "                for i in range(equalization_index+1):\n",
    "                    device_samples[list(sorted_dict.keys())[i]] += diff\n",
    "                samples_to_give_away -= diff*(equalization_index+1)\n",
    "            else: \n",
    "                for samples, dev in distribute(samples_to_give_away, equalization_index+1):\n",
    "                    device_samples[list(sorted_dict.keys())[dev]] += samples\n",
    "                break\n",
    "        else: \n",
    "            for samples, dev in distribute(samples_to_give_away, equalization_index+1):\n",
    "                device_samples[list(sorted_dict.keys())[dev]] += samples\n",
    "            \n",
    "        equalization_index +=1\n",
    "    return {key: device_samples[key] - device_samples_original.get(key, 0) for key in device_samples}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46a5d00",
   "metadata": {},
   "source": [
    "For convenience, we reuse the original KITTI labels (as they still have string names, otherwise just use class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eee92944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "labels_not_in_validation = [x for x in os.listdir(KITTI_DIRECTORY + 'label_2/') if x not in validation]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffe2bf9",
   "metadata": {},
   "source": [
    "Create a mapping of every label file to the classes it contains: e.g.\n",
    " ```'000000.txt': {'Pedestrian'},\n",
    " '000002.txt': {'Car', 'Misc'},\n",
    " '000003.txt': {'Car'},```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "981f681e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5237"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_class_mapping = {}\n",
    "for filename in labels_not_in_validation: \n",
    "    with open(KITTI_DIRECTORY + 'label_2/' + filename, 'r') as file:\n",
    "        file_class_mapping[filename] = set()\n",
    "        for line in file.readlines():\n",
    "            if line.split(\" \")[0] == \"DontCare\":\n",
    "                continue\n",
    "            file_class_mapping[filename].add(line.split(\" \")[0])\n",
    "len(file_class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a12ccaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "c = Counter(frozenset(file_class_mapping[file]) for file in file_class_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e79b04",
   "metadata": {},
   "source": [
    "Use the mapping to distribute classes to each device. E.g. given_classes contains a key for each device, where each device contains a dictionary. The keys in these dictionaries are the set of classes that occur in a label file (which can occur in multiple label files) and the amount of images the device gets from that set. \n",
    "I.e.\n",
    "```0: {frozenset({'Car', 'Misc', 'Pedestrian', 'Truck', 'Van'}): 1,```\n",
    "means device 0 gets 1 image from a file that has labels 'Car', 'Misc', 'Pedestrian', 'Truck' and 'Van'. Only combinations that occur in the label files are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64528831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {frozenset({'Car', 'Misc', 'Pedestrian', 'Truck', 'Van'}): 1,\n",
       "  frozenset({'Car', 'Pedestrian', 'Person_sitting', 'Van'}): 1,\n",
       "  frozenset({'Pedestrian', 'Person_sitting', 'Van'}): 2,\n",
       "  frozenset({'Pedestrian', 'Person_sitting', 'Tram', 'Van'}): 2,\n",
       "  frozenset({'Pedestrian', 'Tram'}): 2,\n",
       "  frozenset({'Pedestrian', 'Person_sitting', 'Tram'}): 3,\n",
       "  frozenset({'Car', 'Pedestrian', 'Person_sitting'}): 2,\n",
       "  frozenset({'Car', 'Misc', 'Pedestrian'}): 3,\n",
       "  frozenset({'Car', 'Pedestrian', 'Tram'}): 6,\n",
       "  frozenset({'Car', 'Tram', 'Truck'}): 4,\n",
       "  frozenset({'Car', 'Pedestrian', 'Truck', 'Van'}): 2,\n",
       "  frozenset({'Car', 'Misc', 'Pedestrian', 'Van'}): 3,\n",
       "  frozenset({'Car', 'Misc', 'Truck'}): 6,\n",
       "  frozenset({'Pedestrian', 'Van'}): 7,\n",
       "  frozenset({'Car', 'Pedestrian', 'Truck'}): 15,\n",
       "  frozenset({'Car', 'Misc', 'Truck', 'Van'}): 8,\n",
       "  frozenset({'Car', 'Tram'}): 16,\n",
       "  frozenset({'Car', 'Pedestrian', 'Van'}): 22,\n",
       "  frozenset({'Car', 'Truck', 'Van'}): 28,\n",
       "  frozenset({'Car', 'Misc', 'Van'}): 15,\n",
       "  frozenset({'Car', 'Misc'}): 28,\n",
       "  frozenset({'Car', 'Pedestrian'}): 39,\n",
       "  frozenset({'Car', 'Truck'}): 60,\n",
       "  frozenset({'Pedestrian'}): 53,\n",
       "  frozenset({'Car', 'Van'}): 53,\n",
       "  frozenset({'Car'}): 199},\n",
       " 1: {frozenset({'Pedestrian', 'Truck'}): 1,\n",
       "  frozenset({'Car', 'Pedestrian', 'Tram', 'Truck'}): 1,\n",
       "  frozenset({'Car', 'Cyclist', 'Pedestrian', 'Truck', 'Van'}): 1,\n",
       "  frozenset({'Car', 'Cyclist', 'Truck', 'Van'}): 1,\n",
       "  frozenset({'Car', 'Cyclist', 'Misc', 'Truck'}): 1,\n",
       "  frozenset({'Car', 'Tram', 'Truck', 'Van'}): 1,\n",
       "  frozenset({'Pedestrian', 'Tram'}): 2,\n",
       "  frozenset({'Misc', 'Pedestrian'}): 1,\n",
       "  frozenset({'Car', 'Cyclist', 'Misc', 'Van'}): 1,\n",
       "  frozenset({'Cyclist', 'Misc', 'Pedestrian'}): 6,\n",
       "  frozenset({'Cyclist', 'Pedestrian', 'Van'}): 7,\n",
       "  frozenset({'Car', 'Tram', 'Truck'}): 2,\n",
       "  frozenset({'Car', 'Pedestrian', 'Truck', 'Van'}): 3,\n",
       "  frozenset({'Car', 'Misc', 'Pedestrian', 'Van'}): 2,\n",
       "  frozenset({'Car', 'Cyclist', 'Truck'}): 8,\n",
       "  frozenset({'Pedestrian', 'Van'}): 6,\n",
       "  frozenset({'Car', 'Cyclist', 'Tram'}): 10,\n",
       "  frozenset({'Car', 'Pedestrian', 'Truck'}): 5,\n",
       "  frozenset({'Cyclist', 'Pedestrian'}): 32,\n",
       "  frozenset({'Car', 'Cyclist', 'Pedestrian', 'Van'}): 36,\n",
       "  frozenset({'Car', 'Cyclist', 'Pedestrian'}): 61,\n",
       "  frozenset({'Car', 'Pedestrian'}): 27,\n",
       "  frozenset({'Car', 'Cyclist'}): 48,\n",
       "  frozenset({'Car', 'Truck'}): 12,\n",
       "  frozenset({'Pedestrian'}): 53,\n",
       "  frozenset({'Car', 'Van'}): 53,\n",
       "  frozenset({'Car'}): 198},\n",
       " 2: {frozenset({'Pedestrian', 'Truck'}): 1,\n",
       "  frozenset({'Car', 'Pedestrian', 'Tram', 'Truck'}): 1,\n",
       "  frozenset({'Car', 'Tram', 'Truck', 'Van'}): 4,\n",
       "  frozenset({'Pedestrian', 'Tram'}): 2,\n",
       "  frozenset({'Car', 'Misc', 'Pedestrian'}): 8,\n",
       "  frozenset({'Car', 'Pedestrian', 'Tram'}): 5,\n",
       "  frozenset({'Car', 'Tram', 'Truck'}): 4,\n",
       "  frozenset({'Car', 'Pedestrian', 'Truck', 'Van'}): 2,\n",
       "  frozenset({'Car', 'Misc', 'Pedestrian', 'Van'}): 3,\n",
       "  frozenset({'Car', 'Misc', 'Truck'}): 7,\n",
       "  frozenset({'Pedestrian', 'Van'}): 7,\n",
       "  frozenset({'Car', 'Pedestrian', 'Truck'}): 15,\n",
       "  frozenset({'Car', 'Misc', 'Truck', 'Van'}): 8,\n",
       "  frozenset({'Car', 'Tram'}): 16,\n",
       "  frozenset({'Car', 'Pedestrian', 'Van'}): 22,\n",
       "  frozenset({'Car', 'Truck', 'Van'}): 27,\n",
       "  frozenset({'Car', 'Misc', 'Van'}): 16,\n",
       "  frozenset({'Car', 'Misc'}): 27,\n",
       "  frozenset({'Car', 'Pedestrian'}): 39,\n",
       "  frozenset({'Car', 'Truck'}): 60,\n",
       "  frozenset({'Pedestrian'}): 53,\n",
       "  frozenset({'Car', 'Van'}): 54,\n",
       "  frozenset({'Car'}): 198},\n",
       " 3: {frozenset({'Car', 'Cyclist', 'Pedestrian', 'Truck', 'Van'}): 2,\n",
       "  frozenset({'Car', 'Cyclist', 'Truck', 'Van'}): 2,\n",
       "  frozenset({'Car', 'Cyclist', 'Misc', 'Truck'}): 1,\n",
       "  frozenset({'Misc', 'Pedestrian'}): 3,\n",
       "  frozenset({'Car', 'Cyclist', 'Misc', 'Van'}): 1,\n",
       "  frozenset({'Cyclist', 'Misc', 'Pedestrian'}): 7,\n",
       "  frozenset({'Cyclist', 'Pedestrian', 'Van'}): 7,\n",
       "  frozenset({'Car', 'Pedestrian', 'Truck', 'Van'}): 4,\n",
       "  frozenset({'Car', 'Misc', 'Pedestrian', 'Van'}): 3,\n",
       "  frozenset({'Car', 'Cyclist', 'Truck'}): 8,\n",
       "  frozenset({'Pedestrian', 'Van'}): 6,\n",
       "  frozenset({'Car', 'Pedestrian', 'Truck'}): 14,\n",
       "  frozenset({'Cyclist', 'Pedestrian'}): 33,\n",
       "  frozenset({'Car', 'Cyclist', 'Pedestrian', 'Van'}): 35,\n",
       "  frozenset({'Car', 'Cyclist', 'Pedestrian'}): 62,\n",
       "  frozenset({'Car', 'Pedestrian'}): 26,\n",
       "  frozenset({'Car', 'Cyclist'}): 49,\n",
       "  frozenset({'Car', 'Truck'}): 11,\n",
       "  frozenset({'Pedestrian'}): 53,\n",
       "  frozenset({'Car', 'Van'}): 53,\n",
       "  frozenset({'Car'}): 199},\n",
       " 4: {frozenset({'Car', 'Cyclist', 'Tram', 'Van'}): 1,\n",
       "  frozenset({'Car', 'Cyclist', 'Person_sitting', 'Van'}): 1,\n",
       "  frozenset({'Car', 'Person_sitting'}): 2,\n",
       "  frozenset({'Car', 'Cyclist', 'Misc', 'Van'}): 5,\n",
       "  frozenset({'Car', 'Cyclist', 'Misc'}): 7,\n",
       "  frozenset({'Car', 'Tram', 'Van'}): 4,\n",
       "  frozenset({'Car', 'Cyclist', 'Tram'}): 34,\n",
       "  frozenset({'Car', 'Cyclist', 'Van'}): 50,\n",
       "  frozenset({'Car', 'Misc', 'Van'}): 44,\n",
       "  frozenset({'Car', 'Misc'}): 27,\n",
       "  frozenset({'Car', 'Cyclist'}): 88,\n",
       "  frozenset({'Car', 'Van'}): 117,\n",
       "  frozenset({'Car'}): 199},\n",
       " 5: {frozenset({'Pedestrian', 'Person_sitting'}): 1,\n",
       "  frozenset({'Car', 'Misc', 'Person_sitting', 'Van'}): 1,\n",
       "  frozenset({'Pedestrian', 'Person_sitting', 'Van'}): 1,\n",
       "  frozenset({'Pedestrian', 'Person_sitting', 'Tram', 'Van'}): 3,\n",
       "  frozenset({'Pedestrian', 'Tram'}): 1,\n",
       "  frozenset({'Pedestrian', 'Person_sitting', 'Tram'}): 4,\n",
       "  frozenset({'Car', 'Pedestrian', 'Person_sitting'}): 2,\n",
       "  frozenset({'Car', 'Misc', 'Pedestrian'}): 2,\n",
       "  frozenset({'Car', 'Pedestrian', 'Tram'}): 6,\n",
       "  frozenset({'Car', 'Misc', 'Pedestrian', 'Van'}): 9,\n",
       "  frozenset({'Pedestrian', 'Van'}): 14,\n",
       "  frozenset({'Car', 'Tram'}): 39,\n",
       "  frozenset({'Car', 'Pedestrian', 'Van'}): 21,\n",
       "  frozenset({'Car', 'Misc', 'Van'}): 44,\n",
       "  frozenset({'Car', 'Misc'}): 27,\n",
       "  frozenset({'Car', 'Pedestrian'}): 39,\n",
       "  frozenset({'Pedestrian'}): 113,\n",
       "  frozenset({'Car', 'Van'}): 53,\n",
       "  frozenset({'Car'}): 199},\n",
       " 6: {frozenset({'Car', 'Pedestrian', 'Person_sitting', 'Van'}): 1,\n",
       "  frozenset({'Pedestrian', 'Person_sitting', 'Van'}): 2,\n",
       "  frozenset({'Car', 'Person_sitting'}): 1,\n",
       "  frozenset({'Misc', 'Pedestrian'}): 4,\n",
       "  frozenset({'Car', 'Pedestrian', 'Person_sitting'}): 4,\n",
       "  frozenset({'Car', 'Misc', 'Pedestrian'}): 3,\n",
       "  frozenset({'Car', 'Pedestrian', 'Truck', 'Van'}): 12,\n",
       "  frozenset({'Car', 'Misc', 'Pedestrian', 'Van'}): 3,\n",
       "  frozenset({'Car', 'Misc', 'Truck'}): 7,\n",
       "  frozenset({'Pedestrian', 'Van'}): 7,\n",
       "  frozenset({'Car', 'Pedestrian', 'Truck'}): 14,\n",
       "  frozenset({'Car', 'Misc', 'Truck', 'Van'}): 8,\n",
       "  frozenset({'Car', 'Pedestrian', 'Van'}): 38,\n",
       "  frozenset({'Car', 'Truck', 'Van'}): 28,\n",
       "  frozenset({'Car', 'Misc', 'Van'}): 15,\n",
       "  frozenset({'Car', 'Misc'}): 28,\n",
       "  frozenset({'Car', 'Pedestrian'}): 39,\n",
       "  frozenset({'Car', 'Truck'}): 60,\n",
       "  frozenset({'Pedestrian'}): 53,\n",
       "  frozenset({'Car', 'Van'}): 53,\n",
       "  frozenset({'Car'}): 199},\n",
       " 7: {frozenset({'Car', 'Cyclist', 'Tram', 'Van'}): 1,\n",
       "  frozenset({'Car', 'Cyclist', 'Person_sitting', 'Van'}): 1,\n",
       "  frozenset({'Car', 'Cyclist', 'Truck', 'Van'}): 1,\n",
       "  frozenset({'Car', 'Cyclist', 'Misc', 'Truck'}): 2,\n",
       "  frozenset({'Car', 'Tram', 'Truck', 'Van'}): 1,\n",
       "  frozenset({'Car', 'Cyclist', 'Misc', 'Van'}): 3,\n",
       "  frozenset({'Car', 'Cyclist', 'Misc'}): 7,\n",
       "  frozenset({'Car', 'Tram', 'Van'}): 3,\n",
       "  frozenset({'Car', 'Tram', 'Truck'}): 6,\n",
       "  frozenset({'Car', 'Cyclist', 'Truck'}): 12,\n",
       "  frozenset({'Car', 'Cyclist', 'Tram'}): 17,\n",
       "  frozenset({'Car', 'Misc', 'Truck', 'Van'}): 12,\n",
       "  frozenset({'Car', 'Cyclist', 'Van'}): 38,\n",
       "  frozenset({'Car', 'Truck', 'Van'}): 28,\n",
       "  frozenset({'Car', 'Misc', 'Van'}): 15,\n",
       "  frozenset({'Car', 'Misc'}): 28,\n",
       "  frozenset({'Car', 'Cyclist'}): 87,\n",
       "  frozenset({'Car', 'Truck'}): 12,\n",
       "  frozenset({'Car', 'Van'}): 106,\n",
       "  frozenset({'Car'}): 199},\n",
       " 8: {frozenset({'Car', 'Misc', 'Person_sitting', 'Van'}): 1,\n",
       "  frozenset({'Car', 'Person_sitting'}): 3,\n",
       "  frozenset({'Car', 'Tram', 'Truck', 'Van'}): 1,\n",
       "  frozenset({'Car', 'Tram', 'Van'}): 14,\n",
       "  frozenset({'Car', 'Tram', 'Truck'}): 6,\n",
       "  frozenset({'Car', 'Misc', 'Truck'}): 11,\n",
       "  frozenset({'Car', 'Misc', 'Truck', 'Van'}): 30,\n",
       "  frozenset({'Car', 'Tram'}): 17,\n",
       "  frozenset({'Car', 'Truck', 'Van'}): 49,\n",
       "  frozenset({'Car', 'Misc', 'Van'}): 15,\n",
       "  frozenset({'Car', 'Misc'}): 28,\n",
       "  frozenset({'Car', 'Truck'}): 99,\n",
       "  frozenset({'Car', 'Van'}): 106,\n",
       "  frozenset({'Car'}): 199}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_set_mapping = {}\n",
    "lisz = c.most_common()\n",
    "lisz.reverse()\n",
    "given_classes = {x: {} for x in CLASS_DEFICIENCIES}\n",
    "for classes, classes_count in lisz:\n",
    "    devices_it_can_be_distributed_over = [x for x in CLASS_DEFICIENCIES if not (CLASS_DEFICIENCIES[x] & classes)]\n",
    "    counts = {device: sum(given_classes[device].values()) for device in devices_it_can_be_distributed_over} \n",
    "    res = determine_how_many_samples_every_device_should_get(counts, classes_count)\n",
    "    for x in res:\n",
    "        if res[x] != 0:\n",
    "            given_classes[x][classes] = res[x]\n",
    "given_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec83cf09",
   "metadata": {},
   "source": [
    "Now create a mapping back from the classes to the files they occur in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8286e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_to_filenr = {}\n",
    "for file in file_class_mapping:\n",
    "    if frozenset(file_class_mapping[file]) not in set_to_filenr:\n",
    "        set_to_filenr[frozenset(file_class_mapping[file])] = []\n",
    "    set_to_filenr[frozenset(file_class_mapping[file])].append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d89e29",
   "metadata": {},
   "source": [
    "Use this mapping to denote which files will go to which device id's:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b6afbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import Random\n",
    "randgen = Random(11111)\n",
    "device_files = {}\n",
    "for device in given_classes:\n",
    "    device_files[device] = []\n",
    "    for class_samples in given_classes[device]:\n",
    "        samples = given_classes[device][class_samples]\n",
    "        for imgid in set_to_filenr[class_samples][:samples]:\n",
    "            device_files[device].append(YOLO_DIRECTORY + 'train/images/' + imgid.split(\".txt\")[0]+\".jpg\\n\")\n",
    "        set_to_filenr[class_samples] = set_to_filenr[class_samples][samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a39d39",
   "metadata": {},
   "source": [
    "And distribute the files to the actual devices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cfdf1884",
   "metadata": {},
   "outputs": [],
   "source": [
    "for device in device_files:\n",
    "    with open(f\"{YOLO_DIRECTORY}/clients/{device}.txt\", \"w\") as f:\n",
    "        randgen.shuffle(device_files[device])\n",
    "        for file in device_files[device]:\n",
    "            f.write(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba67938",
   "metadata": {},
   "source": [
    "To see which devices got which labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2e3c163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'Misc': 64,\n",
       "  'Car': 511,\n",
       "  'Pedestrian': 163,\n",
       "  'Van': 144,\n",
       "  'Truck': 124,\n",
       "  'Person_sitting': 10,\n",
       "  'Tram': 33},\n",
       " 1: {'Truck': 36,\n",
       "  'Pedestrian': 244,\n",
       "  'Tram': 16,\n",
       "  'Car': 471,\n",
       "  'Van': 111,\n",
       "  'Cyclist': 212,\n",
       "  'Misc': 11},\n",
       " 2: {'Truck': 129,\n",
       "  'Pedestrian': 158,\n",
       "  'Tram': 32,\n",
       "  'Car': 516,\n",
       "  'Van': 143,\n",
       "  'Misc': 69},\n",
       " 3: {'Car': 470,\n",
       "  'Pedestrian': 255,\n",
       "  'Van': 113,\n",
       "  'Truck': 42,\n",
       "  'Cyclist': 207,\n",
       "  'Misc': 15},\n",
       " 4: {'Tram': 39,\n",
       "  'Van': 222,\n",
       "  'Car': 579,\n",
       "  'Cyclist': 186,\n",
       "  'Person_sitting': 3,\n",
       "  'Misc': 83},\n",
       " 5: {'Person_sitting': 12,\n",
       "  'Pedestrian': 216,\n",
       "  'Misc': 83,\n",
       "  'Van': 146,\n",
       "  'Car': 442,\n",
       "  'Tram': 53},\n",
       " 6: {'Car': 513,\n",
       "  'Person_sitting': 8,\n",
       "  'Van': 167,\n",
       "  'Pedestrian': 180,\n",
       "  'Misc': 68,\n",
       "  'Truck': 129},\n",
       " 7: {'Tram': 28,\n",
       "  'Van': 209,\n",
       "  'Car': 579,\n",
       "  'Cyclist': 169,\n",
       "  'Person_sitting': 1,\n",
       "  'Truck': 74,\n",
       "  'Misc': 67},\n",
       " 8: {'Person_sitting': 4,\n",
       "  'Misc': 85,\n",
       "  'Van': 216,\n",
       "  'Car': 579,\n",
       "  'Tram': 38,\n",
       "  'Truck': 196}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_counts = {}\n",
    "for device in given_classes:\n",
    "    counts = {}\n",
    "    for sett in given_classes[device]:\n",
    "        for clasz in sett:\n",
    "            if clasz not in counts:\n",
    "                counts[clasz] = 0\n",
    "            counts[clasz] += given_classes[device][sett]\n",
    "    dev_counts[device] = counts\n",
    "dev_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af142e36",
   "metadata": {},
   "source": [
    "### We've now created the 2-class dataset and the 8-class dataset and distributed it over virtual devices. We now continue with the experiments, check the next ipynb notebook. You can delete the files in ./KITTI/training/ to save disk space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3f58a0",
   "metadata": {},
   "source": [
    "## Experiment - AL vs CL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4164e96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAIN_SET = 60\n",
    "DEVICES = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9f560c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import glob\n",
    "random.seed(11111)\n",
    "train_all = glob.glob(os.path.join(YOLO_DIRECTORY + \"train/labels/\", \"*.*\"))\n",
    "random.shuffle(train_all)\n",
    "with open(YOLO_DIRECTORY + \"cl.txt\", \"w\") as f_prefl:\n",
    "    for filename in train_all[:PRETRAIN_SET]:\n",
    "        f_prefl.write('%s\\n' % (filename).replace('labels', 'images').replace('.txt', '.jpg'))\n",
    "cl_size = int(PRETRAIN_SET/DEVICES)\n",
    "cl_count = 0\n",
    "with open(YOLO_DIRECTORY + \"clients/0.txt\", \"w\") as cl1:\n",
    "    for filename in train_all[0:15]:\n",
    "        cl1.write('%s\\n' % (filename).replace('labels', 'images').replace('.txt', '.jpg'))\n",
    "with open(YOLO_DIRECTORY + \"clients/1.txt\", \"w\") as cl2:\n",
    "    for filename in train_all[15:30]:\n",
    "        cl2.write('%s\\n' % (filename).replace('labels', 'images').replace('.txt', '.jpg'))\n",
    "with open(YOLO_DIRECTORY + \"clients/2.txt\", \"w\") as cl3:\n",
    "    for filename in train_all[30:45]:\n",
    "        cl3.write('%s\\n' % (filename).replace('labels', 'images').replace('.txt', '.jpg'))\n",
    "with open(YOLO_DIRECTORY + \"clients/3.txt\", \"w\") as cl4:\n",
    "    for filename in train_all[45:60]:\n",
    "        cl4.write('%s\\n' % (filename).replace('labels', 'images').replace('.txt', '.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdeb4d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "for r in range(20):\n",
    "    print(f\"{r:02d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8cb997",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
