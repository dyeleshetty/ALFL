{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c89ebd6",
   "metadata": {},
   "source": [
    "# Download KITTI Dataset\n",
    "#### Download KITTI Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ed3e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://s3.eu-central-1.amazonaws.com/avg-kitti/data_object_label_2.zip "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f319e832",
   "metadata": {},
   "source": [
    "#### Download KITTI images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dd5b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://s3.eu-central-1.amazonaws.com/avg-kitti/data_object_image_2.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dedd10e",
   "metadata": {},
   "source": [
    "#### Unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad532d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir KITTI\n",
    "!unzip data_object_label_2.zip ./KITTI/\n",
    "!unzip data_object_image_2.zip ./KITTI/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5d28eb",
   "metadata": {},
   "source": [
    "Images are saved in KITTI\\training\\image_2\\, with labels saved in KITTI\\training\\label_2\\. For every image there is a .png and a .txt file containing the labels. The labels are in a special KITTI format (corner coordinates) and converted to the YOLO format (center coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72861aae",
   "metadata": {},
   "source": [
    "# Converting the dataset\n",
    "We create two seperate datasets: the 8-class dataset that is unbalanced, and the 2-class dataset that only contains pedestrians and cars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aab248",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAIN_SET = 200\n",
    "DEVICES = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f455f866",
   "metadata": {},
   "source": [
    "### Converting the 2-Class dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3af287",
   "metadata": {},
   "outputs": [],
   "source": [
    "KITTI_DIRECTORY = './KITTI/training/'\n",
    "YOLO_DIRECTORY = './KITTI/yolo2/'\n",
    "CLASS_MAPPING = {'Car': \"0\", 'Pedestrian': \"1\"}\n",
    "VALIDATION_SPLIT = 0.30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10da3d53",
   "metadata": {},
   "source": [
    "Create folders for 2-class dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080267b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(YOLO_DIRECTORY)\n",
    "os.makedirs(YOLO_DIRECTORY + 'clients/')\n",
    "os.makedirs(YOLO_DIRECTORY + 'train/images/')\n",
    "os.makedirs(YOLO_DIRECTORY + 'train/labels/')\n",
    "os.makedirs(YOLO_DIRECTORY + 'val/images/')\n",
    "os.makedirs(YOLO_DIRECTORY + 'val/labels/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c616393",
   "metadata": {},
   "source": [
    "Create split for training and validationset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47f6038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "random.seed(11111)\n",
    "labels = os.listdir(KITTI_DIRECTORY+\"label_2/\")\n",
    "random.shuffle(labels)\n",
    "split_index = math.floor(len(labels)*VALIDATION_SPLIT)\n",
    "validation = labels[:split_index]\n",
    "train = labels[split_index:]\n",
    "print('Split dataset into {} training items and {} validation items'.format(len(train), len(validation)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5bf6cb",
   "metadata": {},
   "source": [
    "Convert KITTI format to YOLO xywh format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9819a60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_label(label_file, image_width, image_height):\n",
    "    with open(label_file, 'r') as labelfile:\n",
    "        coords = []\n",
    "        all_labels = []\n",
    "        for line in labelfile:\n",
    "            l = line.split(\" \")\n",
    "            # If the class is unknown, don't include in label file.\n",
    "            if not l[0] in CLASS_MAPPING:\n",
    "                continue\n",
    "            \n",
    "            # Convert coordinates to yolo xywh\n",
    "            coords = list(map(int, map(float, l[4:8])))\n",
    "            x = float((float(coords[2]) + float(coords[0])) / 2.0) / float(image_width)\n",
    "            y = float((float(coords[3]) + float(coords[1])) / 2.0) / float(image_height)\n",
    "            width = float(float(coords[2]) - float(coords[0])) / float(image_width)\n",
    "            height = float(float(coords[3]) - float(coords[1])) / float(image_height)\n",
    "            all_labels.append((CLASS_MAPPING[l[0]], [x, y, width, height]))\n",
    "    return all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a072ca45",
   "metadata": {},
   "source": [
    "Use Python Image Library (PIL) to transform the images from png to jpg, to save space and allow more images to be cached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89b2f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def transform_kitti_file(file, folder_prefix):\n",
    "    fname = (KITTI_DIRECTORY + \"image_2/\" + file).split(\".txt\")[0] + \".png\"\n",
    "    if os.path.isfile(fname):\n",
    "        img = Image.open(fname)\n",
    "        img.save(YOLO_DIRECTORY + folder_prefix + \"/images/\" + file.split(\".txt\")[0] + \".jpg\", \"jpeg\")\n",
    "        labels = transform_label(os.path.join(KITTI_DIRECTORY + \"label_2/\" + file), img.size[0], img.size[1])\n",
    "        if len(labels) == 0:\n",
    "            return\n",
    "        with open(YOLO_DIRECTORY + folder_prefix + \"/labels/\" + file, \"a+\") as yolofile:\n",
    "            for l, c, in labels:\n",
    "                yolofile.write(l + \" \" + str(c[0]) + \" \" + str(c[1]) + \" \" + str(c[2]) + \" \" + str(c[3]) + \"\\n\")\n",
    "    else: \n",
    "        print('Image not found for {}'.format(fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f228f85",
   "metadata": {},
   "source": [
    "### Transform Validation and Train sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8d781c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in validation:\n",
    "    transform_kitti_file(f, 'val')\n",
    "for f in train:\n",
    "    transform_kitti_file(f, 'train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19397f13",
   "metadata": {},
   "source": [
    "#### Create overview of all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd6b57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "with open(YOLO_DIRECTORY + \"train_all.txt\", \"w\") as f_train:\n",
    "    for filename in glob.glob(os.path.join(YOLO_DIRECTORY + \"train/labels/\", \"*.*\")):\n",
    "        f_train.write('%s\\n' % (filename).replace('labels', 'images').replace('.txt', '.jpg'))\n",
    "    \n",
    "with open(YOLO_DIRECTORY + \"val.txt\", \"w\") as f_val:\n",
    "    for filename in glob.glob(os.path.join(YOLO_DIRECTORY + \"val/labels/\", \"*.*\")):\n",
    "        f_val.write('%s\\n' % (filename).replace('labels', 'images').replace('.txt', '.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b367a2",
   "metadata": {},
   "source": [
    "### Create pretrain set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5b54a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(11111)\n",
    "train_all = glob.glob(os.path.join(YOLO_DIRECTORY + \"train/labels/\", \"*.*\"))\n",
    "random.shuffle(train_all)\n",
    "with open(YOLO_DIRECTORY + \"pretrain.txt\", \"w\") as f_prefl:\n",
    "    for filename in train_all[:PRETRAIN_SET]:\n",
    "        f_prefl.write('%s\\n' % (filename).replace('labels', 'images').replace('.txt', '.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934f15b4",
   "metadata": {},
   "source": [
    "### Split files over artificial devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3504aaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_integer(num, parts):\n",
    "    quotient, remainder = divmod(num, parts)\n",
    "    lower_elements = [quotient for i in range(parts - remainder)]\n",
    "    higher_elements = [quotient + 1 for j in range(remainder)]\n",
    "    return lower_elements + higher_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c235597",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative = PRETRAIN_SET\n",
    "for i,j in zip(range(0,DEVICES), split_integer(len(train_all)-PRETRAIN_SET, DEVICES)):\n",
    "    print(\"Device {} is receiving {} samples, total: {}/{}\".format(i, j, cumulative-PRETRAIN_SET, len(train_all)-PRETRAIN_SET))\n",
    "    with open(YOLO_DIRECTORY + \"clients/{}.txt\".format(i), \"w\") as f_prefl:\n",
    "        for filename in train_all[cumulative:(cumulative+j)]:\n",
    "            f_prefl.write('%s\\n' % (filename).replace('labels', 'images').replace('.txt', '.jpg'))\n",
    "    cumulative += j\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79974a69",
   "metadata": {},
   "source": [
    "### Converting the 8-Class dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b77dc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "KITTI_DIRECTORY = './KITTI/training/'\n",
    "YOLO_DIRECTORY = './KITTI/yolo8/'\n",
    "CLASS_MAPPING = {'Car': \"0\",\n",
    " 'Cyclist': \"1\",\n",
    " 'Misc': \"2\",\n",
    " 'Pedestrian': \"3\",\n",
    " 'Person_sitting': \"4\",\n",
    " 'Tram': \"5\",\n",
    " 'Truck': \"6\",\n",
    " 'Van': \"7\"}\n",
    "VALIDATION_SPLIT = 0.30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c466db3e",
   "metadata": {},
   "source": [
    "Create folders for 8-class dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffb2126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(YOLO_DIRECTORY)\n",
    "os.makedirs(YOLO_DIRECTORY + 'clients/')\n",
    "os.makedirs(YOLO_DIRECTORY + 'train/images/')\n",
    "os.makedirs(YOLO_DIRECTORY + 'train/labels/')\n",
    "os.makedirs(YOLO_DIRECTORY + 'val/images/')\n",
    "os.makedirs(YOLO_DIRECTORY + 'val/labels/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e98345",
   "metadata": {},
   "source": [
    "Create split for training and validationset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137de39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "random.seed(11111)\n",
    "labels = os.listdir(KITTI_DIRECTORY+\"label_2/\")\n",
    "random.shuffle(labels)\n",
    "split_index = math.floor(len(labels)*VALIDATION_SPLIT)\n",
    "validation = labels[:split_index]\n",
    "train = labels[split_index:]\n",
    "print('Split dataset into {} training items and {} validation items'.format(len(train), len(validation)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefd9d13",
   "metadata": {},
   "source": [
    "#### Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ead2dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in validation:\n",
    "    transform_kitti_file(f, 'val')\n",
    "for f in train:\n",
    "    transform_kitti_file(f, 'train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caea6392",
   "metadata": {},
   "source": [
    "#### Create overview of all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65c66db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "with open(YOLO_DIRECTORY + \"train_all.txt\", \"w\") as f_train:\n",
    "    for filename in glob.glob(os.path.join(YOLO_DIRECTORY + \"train/labels/\", \"*.*\")):\n",
    "        f_train.write('%s\\n' % (filename).replace('labels', 'images').replace('.txt', '.jpg'))\n",
    "    \n",
    "with open(YOLO_DIRECTORY + \"val.txt\", \"w\") as f_val:\n",
    "    for filename in glob.glob(os.path.join(YOLO_DIRECTORY + \"val/labels/\", \"*.*\")):\n",
    "        f_val.write('%s\\n' % (filename).replace('labels', 'images').replace('.txt', '.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af8e586",
   "metadata": {},
   "source": [
    "### Create pretrain set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e2b911",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(11111)\n",
    "train_all = glob.glob(os.path.join(YOLO_DIRECTORY + \"train/labels/\", \"*.*\"))\n",
    "random.shuffle(train_all)\n",
    "with open(YOLO_DIRECTORY + \"pretrain.txt\", \"w\") as f_prefl:\n",
    "    for filename in train_all[:PRETRAIN_SET]:\n",
    "        f_prefl.write('%s\\n' % (filename).replace('labels', 'images').replace('.txt', '.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dffe0b",
   "metadata": {},
   "source": [
    "### Split over devices\n",
    "The device split is significantly more difficult due to the need for an unbalanced dataset. We define the deficiencies for each device below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec933be",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_DEFICIENCIES = {0: {'Cyclist'}, 1:{'Person_sitting'}, 2:{'Cyclist', 'Person_sitting'}, 3: {'Tram', 'Person_sitting'}, \n",
    "                      4: {'Pedestrian', 'Truck'}, 5: {'Truck', 'Cyclist'}, 6: {'Tram', 'Cyclist'}, 7: {'Pedestrian'}, 8: {'Pedestrian', 'Cyclist'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c527f6",
   "metadata": {},
   "source": [
    "Utility functions to distribute the samples over the devices, such that each device has roughly the same amount of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e454e236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribute(samples, devices):\n",
    "    base, extra = divmod(samples, devices)\n",
    "    return [(base + (i < extra),i) for i in range(devices)]\n",
    "\n",
    "def determine_how_many_samples_every_device_should_get(device_samples_original, samples_to_give_away):\n",
    "    equalization_index = 0\n",
    "    device_samples = device_samples_original.copy()\n",
    "    while equalization_index < len(device_samples):\n",
    "        sorted_dict = {k: v for k, v in sorted(device_samples.items(), key=lambda item: item[1], reverse=False)}\n",
    "        if equalization_index + 1 < len(device_samples):\n",
    "            parent = list(sorted_dict.values())[equalization_index+1]\n",
    "            me = list(sorted_dict.values())[equalization_index]\n",
    "            diff = parent-me\n",
    "#             print(f\"equalization_index: {equalization_index}, me: {me}, parent: {parent}, diff: {diff}\")\n",
    "            if diff == 0:\n",
    "                equalization_index +=1\n",
    "                continue\n",
    "            elif diff*(equalization_index+1) < samples_to_give_away:\n",
    "                for i in range(equalization_index+1):\n",
    "                    device_samples[list(sorted_dict.keys())[i]] += diff\n",
    "                samples_to_give_away -= diff*(equalization_index+1)\n",
    "            else: \n",
    "                for samples, dev in distribute(samples_to_give_away, equalization_index+1):\n",
    "                    device_samples[list(sorted_dict.keys())[dev]] += samples\n",
    "                break\n",
    "        else: \n",
    "            for samples, dev in distribute(samples_to_give_away, equalization_index+1):\n",
    "                device_samples[list(sorted_dict.keys())[dev]] += samples\n",
    "            \n",
    "        equalization_index +=1\n",
    "    return {key: device_samples[key] - device_samples_original.get(key, 0) for key in device_samples}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46a5d00",
   "metadata": {},
   "source": [
    "For convenience, we reuse the original KITTI labels (as they still have string names, otherwise just use class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee92944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "labels_not_in_validation = [x for x in os.listdir(KITTI_DIRECTORY + 'label_2/') if x not in validation]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffe2bf9",
   "metadata": {},
   "source": [
    "Create a mapping of every label file to the classes it contains: e.g.\n",
    " ```'000000.txt': {'Pedestrian'},\n",
    " '000002.txt': {'Car', 'Misc'},\n",
    " '000003.txt': {'Car'},```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981f681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_class_mapping = {}\n",
    "for filename in labels_not_in_validation: \n",
    "    with open(KITTI_DIRECTORY + 'label_2/' + filename, 'r') as file:\n",
    "        file_class_mapping[filename] = set()\n",
    "        for line in file.readlines():\n",
    "            if line.split(\" \")[0] == \"DontCare\":\n",
    "                continue\n",
    "            file_class_mapping[filename].add(line.split(\" \")[0])\n",
    "len(file_class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12ccaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "c = Counter(frozenset(file_class_mapping[file]) for file in file_class_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e79b04",
   "metadata": {},
   "source": [
    "Use the mapping to distribute classes to each device. E.g. given_classes contains a key for each device, where each device contains a dictionary. The keys in these dictionaries are the set of classes that occur in a label file (which can occur in multiple label files) and the amount of images the device gets from that set. \n",
    "I.e.\n",
    "```0: {frozenset({'Car', 'Misc', 'Pedestrian', 'Truck', 'Van'}): 1,```\n",
    "means device 0 gets 1 image from a file that has labels 'Car', 'Misc', 'Pedestrian', 'Truck' and 'Van'. Only combinations that occur in the label files are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64528831",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_set_mapping = {}\n",
    "lisz = c.most_common()\n",
    "lisz.reverse()\n",
    "given_classes = {x: {} for x in CLASS_DEFICIENCIES}\n",
    "for classes, classes_count in lisz:\n",
    "    devices_it_can_be_distributed_over = [x for x in CLASS_DEFICIENCIES if not (CLASS_DEFICIENCIES[x] & classes)]\n",
    "    counts = {device: sum(given_classes[device].values()) for device in devices_it_can_be_distributed_over} \n",
    "    res = determine_how_many_samples_every_device_should_get(counts, classes_count)\n",
    "    for x in res:\n",
    "        if res[x] != 0:\n",
    "            given_classes[x][classes] = res[x]\n",
    "given_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec83cf09",
   "metadata": {},
   "source": [
    "Now create a mapping back from the classes to the files they occur in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8286e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_to_filenr = {}\n",
    "for file in file_class_mapping:\n",
    "    if frozenset(file_class_mapping[file]) not in set_to_filenr:\n",
    "        set_to_filenr[frozenset(file_class_mapping[file])] = []\n",
    "    set_to_filenr[frozenset(file_class_mapping[file])].append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d89e29",
   "metadata": {},
   "source": [
    "Use this mapping to denote which files will go to which device id's:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6afbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import Random\n",
    "randgen = Random(11111)\n",
    "device_files = {}\n",
    "for device in given_classes:\n",
    "    device_files[device] = []\n",
    "    for class_samples in given_classes[device]:\n",
    "        samples = given_classes[device][class_samples]\n",
    "        for imgid in set_to_filenr[class_samples][:samples]:\n",
    "            device_files[device].append(YOLO_DIRECTORY + 'train/images/' + imgid.split(\".txt\")[0]+\".jpg\\n\")\n",
    "        set_to_filenr[class_samples] = set_to_filenr[class_samples][samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a39d39",
   "metadata": {},
   "source": [
    "And distribute the files to the actual devices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdf1884",
   "metadata": {},
   "outputs": [],
   "source": [
    "for device in device_files:\n",
    "    with open(f\"{YOLO_DIRECTORY}/clients/{device}.txt\", \"w\") as f:\n",
    "        randgen.shuffle(device_files[device])\n",
    "        for file in device_files[device]:\n",
    "            f.write(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba67938",
   "metadata": {},
   "source": [
    "To see which devices got which labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e3c163",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_counts = {}\n",
    "for device in given_classes:\n",
    "    counts = {}\n",
    "    for sett in given_classes[device]:\n",
    "        for clasz in sett:\n",
    "            if clasz not in counts:\n",
    "                counts[clasz] = 0\n",
    "            counts[clasz] += given_classes[device][sett]\n",
    "    dev_counts[device] = counts\n",
    "dev_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af142e36",
   "metadata": {},
   "source": [
    "### We've now created the 2-class dataset and the 8-class dataset and distributed it over virtual devices. We now continue with the experiments, check the next ipynb notebook. You can delete the files in ./KITTI/training/ to save disk space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f560c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
