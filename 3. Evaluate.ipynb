{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30d8c1c5",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "The evaluation is done after the training, not during the training. This is because the evaluation can then be executed on a seperate computer with less resources, while the powerful computers continue training. Two dataloaders are created, one for the 2-class dataset and one for the 8-class dataset. The validation set is used to calculate the common metrics, which are then stored in a .pickle file, which are used in 4 to analyse and graph the results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3046b23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gc\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from threading import Thread\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models.experimental import attempt_load\n",
    "from utils.datasets import create_dataloader\n",
    "from utils.general import coco80_to_coco91_class, check_dataset, check_file, check_img_size, check_requirements, \\\n",
    "    box_iou, non_max_suppression, scale_coords, xyxy2xywh, xywh2xyxy, set_logging, increment_path, colorstr\n",
    "from utils.loss import ComputeLoss\n",
    "from utils.metrics import ap_per_class, ConfusionMatrix\n",
    "from utils.plots import plot_images, output_to_target, plot_study_txt\n",
    "from utils.torch_utils import select_device, time_synchronized\n",
    "\n",
    "batch_size = 64\n",
    "imgsz = 640\n",
    "conf_thres=0.001\n",
    "plots=True\n",
    "iou_thres=0.6\n",
    "gs = 32 # gridsize (max stride of model)\n",
    "set_logging()\n",
    "device = select_device('', batch_size=batch_size)\n",
    "# Half\n",
    "half = device.type != 'cpu'  # half precision only supported on CUDA\n",
    "class opt: pass\n",
    "opt.single_cls = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99db689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(weights):\n",
    "    w = Path(weights[0] if isinstance(weights, list) else weights).stem if weights is not None else ''  # weights\n",
    "    if w == 'best' or w == 'last':\n",
    "        w = weights.split('\\\\')[4].replace(\"run-26-\", \"run-15-\")\n",
    "    save_dir = increment_path(Path('runs/val/') / w, exist_ok=False)  # increment run\n",
    "    (save_dir / 'labels').mkdir(parents=True, exist_ok=True)  # make dir\n",
    "    # PREP MODEL\n",
    "    model = attempt_load(weights, map_location=device)  # load FP32 model\n",
    "    if half:\n",
    "        model.half()\n",
    "    # Configure\n",
    "    model.eval()\n",
    "    if device.type != 'cpu':\n",
    "        model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))  # run once\n",
    "    iouv = torch.linspace(0.5, 0.95, 10).to(device)  # iou vector for mAP@0.5:0.95\n",
    "    niou = iouv.numel()\n",
    "    # PREP COMPUTE LOSS\n",
    "    compute_loss = ComputeLoss(model)\n",
    "    \n",
    "    seen = 0\n",
    "    confusion_matrix = ConfusionMatrix(nc=nc)\n",
    "    names = {k: v for k, v in enumerate(model.names if hasattr(model, 'names') else model.module.names)}\n",
    "    s = ('%20s' + '%12s' * 6) % ('Class', 'Images', 'Labels', 'P', 'R', 'mAP@.5', 'mAP@.5:.95')\n",
    "    p, r, f1, mp, mr, map50, map, t0, t1 = 0., 0., 0., 0., 0., 0., 0., 0., 0.\n",
    "    loss = torch.zeros(3, device=device)\n",
    "    jdict, stats, ap, ap_class, wandb_images = [], [], [], [], []\n",
    "    for batch_i, (img, targets, paths, shapes) in enumerate(tqdm(dataloader, desc=s)):\n",
    "        img = img.to(device, non_blocking=True)\n",
    "        img = img.half() if half else img.float()  # uint8 to fp16/32\n",
    "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "        targets = targets.to(device)\n",
    "        nb, _, height, width = img.shape  # batch size, channels, height, width\n",
    "\n",
    "        # Run model\n",
    "        t = time_synchronized()\n",
    "        out, train_out = model(img, augment=False)  # inference and training outputs\n",
    "        t0 += time_synchronized() - t\n",
    "\n",
    "        # Compute loss\n",
    "        if compute_loss:\n",
    "            loss += compute_loss([x.float() for x in train_out], targets)[1][:3]  # box, obj, cls\n",
    "\n",
    "        # Run NMS\n",
    "        targets[:, 2:] *= torch.Tensor([width, height, width, height]).to(device)  # to pixels\n",
    "        out = non_max_suppression(out, conf_thres, iou_thres, labels=[], multi_label=True, agnostic=False)\n",
    "\n",
    "        # Statistics per image\n",
    "        for si, pred in enumerate(out):\n",
    "            labels = targets[targets[:, 0] == si, 1:]\n",
    "            nl = len(labels)\n",
    "            tcls = labels[:, 0].tolist() if nl else []  # target class\n",
    "            path = Path(paths[si])\n",
    "            seen += 1\n",
    "\n",
    "            if len(pred) == 0:\n",
    "                if nl:\n",
    "                    stats.append((torch.zeros(0, niou, dtype=torch.bool), torch.Tensor(), torch.Tensor(), tcls))\n",
    "                continue\n",
    "\n",
    "            # Predictions\n",
    "            predn = pred.clone()\n",
    "            scale_coords(img[si].shape[1:], predn[:, :4], shapes[si][0], shapes[si][1])  # native-space pred\n",
    "\n",
    "            image_id = int(path.stem) if path.stem.isnumeric() else path.stem\n",
    "            box = xyxy2xywh(predn[:, :4])  # xywh\n",
    "            box[:, :2] -= box[:, 2:] / 2  # xy center to top-left corner\n",
    "            for p, b in zip(pred.tolist(), box.tolist()):\n",
    "                jdict.append({'image_id': image_id,\n",
    "                              'category_id': int(p[5]),\n",
    "                              'bbox': [round(x, 3) for x in b],\n",
    "                              'score': round(p[4], 5)})\n",
    "\n",
    "            # Assign all predictions as incorrect\n",
    "            correct = torch.zeros(pred.shape[0], niou, dtype=torch.bool, device=device)\n",
    "            if nl:\n",
    "                detected = []  # target indices\n",
    "                tcls_tensor = labels[:, 0]\n",
    "\n",
    "                # target boxes\n",
    "                tbox = xywh2xyxy(labels[:, 1:5])\n",
    "                scale_coords(img[si].shape[1:], tbox, shapes[si][0], shapes[si][1])  # native-space labels\n",
    "                if plots:\n",
    "                    confusion_matrix.process_batch(predn, torch.cat((labels[:, 0:1], tbox), 1))\n",
    "\n",
    "                # Per target class\n",
    "                for cls in torch.unique(tcls_tensor):\n",
    "                    ti = (cls == tcls_tensor).nonzero(as_tuple=False).view(-1)  # target indices\n",
    "                    pi = (cls == pred[:, 5]).nonzero(as_tuple=False).view(-1)  # prediction indices\n",
    "\n",
    "                    # Search for detections\n",
    "                    if pi.shape[0]:\n",
    "                        # Prediction to target ious\n",
    "                        ious, i = box_iou(predn[pi, :4], tbox[ti]).max(1)  # best ious, indices\n",
    "\n",
    "                        # Append detections\n",
    "                        detected_set = set()\n",
    "                        for j in (ious > iouv[0]).nonzero(as_tuple=False):\n",
    "                            d = ti[i[j]]  # detected target\n",
    "                            if d.item() not in detected_set:\n",
    "                                detected_set.add(d.item())\n",
    "                                detected.append(d)\n",
    "                                correct[pi[j]] = ious[j] > iouv  # iou_thres is 1xn\n",
    "                                if len(detected) == nl:  # all targets already located in image\n",
    "                                    break\n",
    "\n",
    "            # Append statistics (correct, conf, pcls, tcls)\n",
    "            stats.append((correct.cpu(), pred[:, 4].cpu(), pred[:, 5].cpu(), tcls))\n",
    "\n",
    "        # Plot images\n",
    "        if plots and batch_i < 3:\n",
    "            f = save_dir / f'test_batch{batch_i}_labels.jpg'  # labels\n",
    "            Thread(target=plot_images, args=(img, targets, paths, f, names), daemon=True).start()\n",
    "            f = save_dir / f'test_batch{batch_i}_pred.jpg'  # predictions\n",
    "            Thread(target=plot_images, args=(img, output_to_target(out), paths, f, names), daemon=True).start()\n",
    "\n",
    "    # Compute statistics\n",
    "    stats = [np.concatenate(x, 0) for x in zip(*stats)]  # to numpy\n",
    "    if len(stats) and stats[0].any():\n",
    "        p, r, ap, f1, ap_class = ap_per_class(*stats, plot=plots, save_dir=save_dir, names=names)\n",
    "        ap50, ap = ap[:, 0], ap.mean(1)  # AP@0.5, AP@0.5:0.95\n",
    "        mp, mr, map50, map = p.mean(), r.mean(), ap50.mean(), ap.mean()\n",
    "        nt = np.bincount(stats[3].astype(np.int64), minlength=nc)  # number of targets per class\n",
    "    else:\n",
    "        nt = torch.zeros(1)\n",
    "    a = {'p': p,\n",
    "         'r': r,\n",
    "         'ap': ap,\n",
    "         'f1': f1,\n",
    "         'ap_class': ap_class,\n",
    "         'ap50': ap50,\n",
    "         'mp': mp,\n",
    "         'mr': mr,\n",
    "         'map50':map50,\n",
    "         'map':map,\n",
    "         'nt': nt,\n",
    "         'names':names,\n",
    "         'res_per_class': [(names[c], seen, nt[c], p[i], r[i], ap50[i], ap[i]) for i,c in enumerate(ap_class)],\n",
    "         'conf_matrix': confusion_matrix.matrix,\n",
    "         'losses': (loss.cpu() / len(dataloader)).tolist()}\n",
    "\n",
    "    with open(f'./evals/{w}.pickle', 'wb') as handle:\n",
    "        pickle.dump(a, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    if len(jdict):\n",
    "        pred_json = str(save_dir / f\"{w}_predictions.json\")  # predictions json\n",
    "        print('\\nsaving json %s...' % pred_json)\n",
    "        with open(pred_json, 'w') as f:\n",
    "            json.dump(jdict, f)\n",
    "            \n",
    "    # Print results\n",
    "    pf = '%20s' + '%12i' * 2 + '%12.3g' * 4  # print format\n",
    "    print(pf % ('all', seen, nt.sum(), mp, mr, map50, map))\n",
    "\n",
    "    # Print results per class\n",
    "    for i, c in enumerate(ap_class):\n",
    "        print(pf % (names[c], seen, nt[c], p[i], r[i], ap50[i], ap[i]))\n",
    "\n",
    "    # Plots\n",
    "    confusion_matrix.plot(save_dir=save_dir, names=list(names.values()))\n",
    "    del model\n",
    "    \n",
    "    return (mp, mr, map50, map, *(loss.cpu() / len(dataloader)).tolist()), maps, t, save_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff7c847",
   "metadata": {},
   "source": [
    "## Evaluating 2-class sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedf9c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = create_dataloader(f'KITTI/yolo2/val.txt', imgsz, batch_size, gs, opt, pad=0.5, rect=True, prefix=colorstr('val2: '))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec08d65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = 2\n",
    "for file in glob.glob('pseudo_fl/*.pt'):\n",
    "    evaluate(file)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407df7d8",
   "metadata": {},
   "source": [
    "## Evaluating 8-class sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb6024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = create_dataloader(f'KITTI/yolo8/val.txt', imgsz, batch_size, gs, opt, pad=0.5, rect=True, prefix=colorstr('val8: '))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf710b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = 8\n",
    "for file in glob.glob(\"D:\\\\Research Project\\\\8_Chained\\\\Runs\\\\*\\\\weights\\\\best.pt\", recursive=True):\n",
    "    evaluate(file, dataloader8)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
