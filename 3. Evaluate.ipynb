{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30d8c1c5",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "The evaluation is done after the training, not during the training. This is because the evaluation can then be executed on a seperate computer with less resources, while the powerful computers continue training. Two dataloaders are created, one for the 2-class dataset and one for the 8-class dataset. The validation set is used to calculate the common metrics, which are then stored in a .pickle file, which are used in 4 to analyse and graph the results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "comfortable-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import glob\n",
    "import gc\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "radio-injection",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[34m\u001b[1mval2: \u001b[0mScanning 'KITTI\\yolo2\\val.cache' images and labels... 2244 found, 0 missing, 0 empty, 0 corrupted: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2244/2244 [00:00<?, ?it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jelte\\PycharmProjects\\ALFL-clean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval2: \u001b[0mScanning 'KITTI\\yolo2\\val.cache' images and labels... 2244 found, 0 missing, 0 empty, 0 corrupted: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2244/2244 [00:00<?, ?it/s]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dataloader = evaluate.get_dataloader(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "associate-calculation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  5639932 torch 1.8.0+cu111 CUDA:0 (GeForce RTX 3080, 10240.0MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 224 layers, 7056607 parameters, 0 gradients\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:15<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "saving json runs\\val\\fed-12-280\\fed-12-280_predictions.json...\n",
      "                 all        2244       10080       0.797       0.686       0.753       0.403\n",
      "                 car        2244        8748       0.867       0.828       0.893       0.562\n",
      "          pedestrian        2244        1332       0.727       0.543       0.613       0.244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0.7973857093665015,\n",
       "  0.6855405413755431,\n",
       "  0.7531716917426254,\n",
       "  0.4030898796118148,\n",
       "  0.036653388291597366,\n",
       "  0.04719178006052971,\n",
       "  0.0010762033052742481),\n",
       " array([    0.56187,      0.2443]),\n",
       " 1627586715.8881018,\n",
       " {'p': array([    0.86745,     0.72732]),\n",
       "  'r': array([    0.82842,     0.54266]),\n",
       "  'ap': array([    0.56187,      0.2443]),\n",
       "  'f1': array([    0.84749,     0.62157]),\n",
       "  'ap_class': array([0, 1]),\n",
       "  'ap50': array([    0.89337,     0.61297]),\n",
       "  'mp': 0.7973857093665015,\n",
       "  'mr': 0.6855405413755431,\n",
       "  'map50': 0.7531716917426254,\n",
       "  'map': 0.4030898796118148,\n",
       "  'nt': array([8748, 1332], dtype=int64),\n",
       "  'names': {0: 'car', 1: 'pedestrian'},\n",
       "  'res_per_class': [('car',\n",
       "    2244,\n",
       "    8748,\n",
       "    0.867454642237468,\n",
       "    0.8284179240969365,\n",
       "    0.8933718715658732,\n",
       "    0.5618748728565351),\n",
       "   ('pedestrian',\n",
       "    2244,\n",
       "    1332,\n",
       "    0.727316776495535,\n",
       "    0.5426631586541497,\n",
       "    0.6129715119193777,\n",
       "    0.24430488636709446)],\n",
       "  'conf_matrix': array([[       7668,           3,        2227],\n",
       "         [          1,         856,         600],\n",
       "         [       1079,         470,           0]]),\n",
       "  'losses': [0.036653388291597366,\n",
       "   0.04719178006052971,\n",
       "   0.0010762033052742481]})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate.evaluate('pseudo_fl/fed-12-280.pt', None, None, dataloader, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "helpful-chapel",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  5639932 torch 1.8.0+cu111 CUDA:0 (GeForce RTX 3080, 10240.0MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 224 layers, 7056607 parameters, 0 gradients\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:15<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "saving json runs\\val\\fed-12-200\\fed-12-200_predictions.json...\n",
      "                 all        2244       10080       0.776       0.699       0.749       0.401\n",
      "                 car        2244        8748       0.839       0.845       0.889       0.561\n",
      "          pedestrian        2244        1332       0.713       0.553       0.609       0.242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0.7757478192206549,\n",
       "  0.6993768459817843,\n",
       "  0.7489088930854142,\n",
       "  0.4014253977873569,\n",
       "  0.03673572465777397,\n",
       "  0.04773494601249695,\n",
       "  0.001078975386917591),\n",
       " array([    0.56111,     0.24174]),\n",
       " 1627563495.0057209,\n",
       " {'p': array([    0.83874,     0.71276]),\n",
       "  'r': array([    0.84545,      0.5533]),\n",
       "  'ap': array([    0.56111,     0.24174]),\n",
       "  'f1': array([    0.84208,     0.62299]),\n",
       "  'ap_class': array([0, 1]),\n",
       "  'ap50': array([    0.88882,     0.60899]),\n",
       "  'mp': 0.7757478192206549,\n",
       "  'mr': 0.6993768459817843,\n",
       "  'map50': 0.7489088930854142,\n",
       "  'map': 0.4014253977873569,\n",
       "  'nt': array([8748, 1332], dtype=int64),\n",
       "  'names': {0: 'car', 1: 'pedestrian'},\n",
       "  'res_per_class': [('car',\n",
       "    2244,\n",
       "    8748,\n",
       "    0.8387362298395743,\n",
       "    0.8454503886602652,\n",
       "    0.8888245039975653,\n",
       "    0.5611081534949793),\n",
       "   ('pedestrian',\n",
       "    2244,\n",
       "    1332,\n",
       "    0.7127594086017356,\n",
       "    0.5533033033033034,\n",
       "    0.608993282173263,\n",
       "    0.24174264207973448)],\n",
       "  'conf_matrix': array([[       7763,           2,        2473],\n",
       "         [          4,         850,         604],\n",
       "         [        981,         477,           0]]),\n",
       "  'losses': [0.03673572465777397, 0.04773494601249695, 0.001078975386917591]})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate.evaluate('pseudo_fl/fed-12-200.pt', None, None, dataloader, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alone-timer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  5639932 torch 1.8.0+cu111 CUDA:0 (GeForce RTX 3080, 10240.0MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 224 layers, 7056607 parameters, 0 gradients\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:16<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "saving json runs\\val\\fed-12-121\\fed-12-121_predictions.json...\n",
      "                 all        2244       10080       0.779       0.674       0.745       0.391\n",
      "                 car        2244        8748       0.834       0.825       0.887       0.546\n",
      "          pedestrian        2244        1332       0.725       0.523       0.603       0.236\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0.7793613773252648,\n",
       "  0.6736047318466157,\n",
       "  0.7450895779553562,\n",
       "  0.3906007434822122,\n",
       "  0.037519458681344986,\n",
       "  0.04604988545179367,\n",
       "  0.0010285453172400594),\n",
       " array([    0.54552,     0.23568]),\n",
       " 1627513494.777964,\n",
       " {'p': array([      0.834,     0.72473]),\n",
       "  'r': array([    0.82469,     0.52252]),\n",
       "  'ap': array([    0.54552,     0.23568]),\n",
       "  'f1': array([    0.82932,     0.60723]),\n",
       "  'ap_class': array([0, 1]),\n",
       "  'ap50': array([    0.88734,     0.60284]),\n",
       "  'mp': 0.7793613773252648,\n",
       "  'mr': 0.6736047318466157,\n",
       "  'map50': 0.7450895779553562,\n",
       "  'map': 0.3906007434822122,\n",
       "  'nt': array([8748, 1332], dtype=int64),\n",
       "  'names': {0: 'car', 1: 'pedestrian'},\n",
       "  'res_per_class': [('car',\n",
       "    2244,\n",
       "    8748,\n",
       "    0.8339953737837106,\n",
       "    0.824686941170709,\n",
       "    0.8873396108267833,\n",
       "    0.5455226080248707),\n",
       "   ('pedestrian',\n",
       "    2244,\n",
       "    1332,\n",
       "    0.724727380866819,\n",
       "    0.5225225225225225,\n",
       "    0.6028395450839292,\n",
       "    0.23567887893955364)],\n",
       "  'conf_matrix': array([[       7638,           2,        2484],\n",
       "         [          0,         812,         492],\n",
       "         [       1110,         518,           0]]),\n",
       "  'losses': [0.037519458681344986,\n",
       "   0.04604988545179367,\n",
       "   0.0010285453172400594]})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate.evaluate('pseudo_fl/fed-12-200.pt', None, None, dataloader, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff7c847",
   "metadata": {},
   "source": [
    "## Evaluating 2-class sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cedf9c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jelte\\PycharmProjects\\ALFL-clean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval2: \u001b[0mScanning 'KITTI\\yolo2\\val.cache' images and labels... 2244 found, 0 missing, 0 empty, 0 corrupted: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2244/2244 [00:00<?, ?it/s]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dataloader = evaluate.get_dataloader(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec08d65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in glob.glob('runs/*/weights/best.pt'):\n",
    "    evaluate.evaluate(file, None, None, dataloader, 2)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407df7d8",
   "metadata": {},
   "source": [
    "## Evaluating 8-class sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb6024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = create_dataloader(f'KITTI/yolo8/val.txt', imgsz, batch_size, gs, opt, pad=0.5, rect=True, prefix=colorstr('val8: '))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf710b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = 8\n",
    "for file in glob.glob(\"D:\\\\Research Project\\\\8_Chained\\\\Runs\\\\*\\\\weights\\\\best.pt\", recursive=True):\n",
    "    evaluate.evaluate(file, None, None, dataloader, 8)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
